{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trader Performance vs Market Sentiment Analysis\n",
    "## Hyperliquid Trading Behavior Study\n",
    "\n",
    "**Objective**: Analyze the relationship between market sentiment (Fear/Greed) and trader behavior/performance on Hyperliquid to identify actionable trading strategies.\n",
    "\n",
    "**Author**: Data Science Intern Candidate  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical testing\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, chi2_contingency\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part A: Data Preparation & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Datasets\n",
    "\n",
    "**Note**: Download the datasets from the provided Google Drive links and place them in the `data/` folder:\n",
    "- `bitcoin_sentiment.csv` - Bitcoin Market Sentiment (Fear/Greed)\n",
    "- `trader_data.csv` - Historical Trader Data from Hyperliquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SENTIMENT DATA\n",
      "============================================================\n",
      "Shape: (2644, 4)\n",
      "Columns: ['timestamp', 'value', 'classification', 'date']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>classification</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1517463000</td>\n",
       "      <td>30</td>\n",
       "      <td>Fear</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1517549400</td>\n",
       "      <td>15</td>\n",
       "      <td>Extreme Fear</td>\n",
       "      <td>2018-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1517635800</td>\n",
       "      <td>40</td>\n",
       "      <td>Fear</td>\n",
       "      <td>2018-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1517722200</td>\n",
       "      <td>24</td>\n",
       "      <td>Extreme Fear</td>\n",
       "      <td>2018-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1517808600</td>\n",
       "      <td>11</td>\n",
       "      <td>Extreme Fear</td>\n",
       "      <td>2018-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  value classification        date\n",
       "0  1517463000     30           Fear  2018-02-01\n",
       "1  1517549400     15   Extreme Fear  2018-02-02\n",
       "2  1517635800     40           Fear  2018-02-03\n",
       "3  1517722200     24   Extreme Fear  2018-02-04\n",
       "4  1517808600     11   Extreme Fear  2018-02-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "timestamp          int64\n",
      "value              int64\n",
      "classification    object\n",
      "date              object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "timestamp         0\n",
      "value             0\n",
      "classification    0\n",
      "date              0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Load sentiment data\n",
    "sentiment_df = pd.read_csv('../data/fear_greed_index.csv')\n",
    "print(\"=\" * 60)\n",
    "print(\"SENTIMENT DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {sentiment_df.shape}\")\n",
    "print(f\"Columns: {list(sentiment_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(sentiment_df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(sentiment_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(sentiment_df.isnull().sum())\n",
    "print(f\"\\nDuplicate rows: {sentiment_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRADER DATA\n",
      "============================================================\n",
      "Shape: (211224, 16)\n",
      "Columns: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side', 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account</th>\n",
       "      <th>Coin</th>\n",
       "      <th>Execution Price</th>\n",
       "      <th>Size Tokens</th>\n",
       "      <th>Size USD</th>\n",
       "      <th>Side</th>\n",
       "      <th>Timestamp IST</th>\n",
       "      <th>Start Position</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Closed PnL</th>\n",
       "      <th>Transaction Hash</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Crossed</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Trade ID</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xae5eacaf9c6b9111fd53034a602c192a04e082ed</td>\n",
       "      <td>@107</td>\n",
       "      <td>7.9769</td>\n",
       "      <td>986.87</td>\n",
       "      <td>7872.16</td>\n",
       "      <td>BUY</td>\n",
       "      <td>02-12-2024 22:50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0xec09451986a1874e3a980418412fcd0201f500c95bac...</td>\n",
       "      <td>52017706630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.345404</td>\n",
       "      <td>8.950000e+14</td>\n",
       "      <td>1.730000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xae5eacaf9c6b9111fd53034a602c192a04e082ed</td>\n",
       "      <td>@107</td>\n",
       "      <td>7.9800</td>\n",
       "      <td>16.00</td>\n",
       "      <td>127.68</td>\n",
       "      <td>BUY</td>\n",
       "      <td>02-12-2024 22:50</td>\n",
       "      <td>986.524596</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0xec09451986a1874e3a980418412fcd0201f500c95bac...</td>\n",
       "      <td>52017706630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>4.430000e+14</td>\n",
       "      <td>1.730000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xae5eacaf9c6b9111fd53034a602c192a04e082ed</td>\n",
       "      <td>@107</td>\n",
       "      <td>7.9855</td>\n",
       "      <td>144.09</td>\n",
       "      <td>1150.63</td>\n",
       "      <td>BUY</td>\n",
       "      <td>02-12-2024 22:50</td>\n",
       "      <td>1002.518996</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0xec09451986a1874e3a980418412fcd0201f500c95bac...</td>\n",
       "      <td>52017706630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>6.600000e+14</td>\n",
       "      <td>1.730000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xae5eacaf9c6b9111fd53034a602c192a04e082ed</td>\n",
       "      <td>@107</td>\n",
       "      <td>7.9874</td>\n",
       "      <td>142.98</td>\n",
       "      <td>1142.04</td>\n",
       "      <td>BUY</td>\n",
       "      <td>02-12-2024 22:50</td>\n",
       "      <td>1146.558564</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0xec09451986a1874e3a980418412fcd0201f500c95bac...</td>\n",
       "      <td>52017706630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050043</td>\n",
       "      <td>1.080000e+15</td>\n",
       "      <td>1.730000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xae5eacaf9c6b9111fd53034a602c192a04e082ed</td>\n",
       "      <td>@107</td>\n",
       "      <td>7.9894</td>\n",
       "      <td>8.73</td>\n",
       "      <td>69.75</td>\n",
       "      <td>BUY</td>\n",
       "      <td>02-12-2024 22:50</td>\n",
       "      <td>1289.488521</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0xec09451986a1874e3a980418412fcd0201f500c95bac...</td>\n",
       "      <td>52017706630</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>1.050000e+15</td>\n",
       "      <td>1.730000e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Account  Coin  Execution Price  \\\n",
       "0  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9769   \n",
       "1  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9800   \n",
       "2  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9855   \n",
       "3  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9874   \n",
       "4  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9894   \n",
       "\n",
       "   Size Tokens  Size USD Side     Timestamp IST  Start Position Direction  \\\n",
       "0       986.87   7872.16  BUY  02-12-2024 22:50        0.000000       Buy   \n",
       "1        16.00    127.68  BUY  02-12-2024 22:50      986.524596       Buy   \n",
       "2       144.09   1150.63  BUY  02-12-2024 22:50     1002.518996       Buy   \n",
       "3       142.98   1142.04  BUY  02-12-2024 22:50     1146.558564       Buy   \n",
       "4         8.73     69.75  BUY  02-12-2024 22:50     1289.488521       Buy   \n",
       "\n",
       "   Closed PnL                                   Transaction Hash     Order ID  \\\n",
       "0         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
       "1         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
       "2         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
       "3         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
       "4         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
       "\n",
       "   Crossed       Fee      Trade ID     Timestamp  \n",
       "0     True  0.345404  8.950000e+14  1.730000e+12  \n",
       "1     True  0.005600  4.430000e+14  1.730000e+12  \n",
       "2     True  0.050431  6.600000e+14  1.730000e+12  \n",
       "3     True  0.050043  1.080000e+15  1.730000e+12  \n",
       "4     True  0.003055  1.050000e+15  1.730000e+12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "Account              object\n",
      "Coin                 object\n",
      "Execution Price     float64\n",
      "Size Tokens         float64\n",
      "Size USD            float64\n",
      "Side                 object\n",
      "Timestamp IST        object\n",
      "Start Position      float64\n",
      "Direction            object\n",
      "Closed PnL          float64\n",
      "Transaction Hash     object\n",
      "Order ID              int64\n",
      "Crossed                bool\n",
      "Fee                 float64\n",
      "Trade ID            float64\n",
      "Timestamp           float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Account             0\n",
      "Coin                0\n",
      "Execution Price     0\n",
      "Size Tokens         0\n",
      "Size USD            0\n",
      "Side                0\n",
      "Timestamp IST       0\n",
      "Start Position      0\n",
      "Direction           0\n",
      "Closed PnL          0\n",
      "Transaction Hash    0\n",
      "Order ID            0\n",
      "Crossed             0\n",
      "Fee                 0\n",
      "Trade ID            0\n",
      "Timestamp           0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Load trader data\n",
    "trader_df = pd.read_csv('../data/historical_data.csv')\n",
    "print(\"=\" * 60)\n",
    "print(\"TRADER DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {trader_df.shape}\")\n",
    "print(f\"Columns: {list(trader_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(trader_df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(trader_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(trader_df.isnull().sum())\n",
    "print(f\"\\nDuplicate rows: {trader_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned sentiment data shape: (2644, 4)\n",
      "Date range: 2018-02-01 00:00:00 to 2025-05-02 00:00:00\n",
      "\n",
      "Sentiment distribution:\n",
      "classification\n",
      "Fear             781\n",
      "Greed            633\n",
      "Extreme Fear     508\n",
      "Neutral          396\n",
      "Extreme Greed    326\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean sentiment data\n",
    "sentiment_clean = sentiment_df.copy()\n",
    "\n",
    "# Convert date column to datetime\n",
    "sentiment_clean['date'] = pd.to_datetime(sentiment_clean['date'])\n",
    "\n",
    "# Remove duplicates (keep last entry per date)\n",
    "sentiment_clean = sentiment_clean.drop_duplicates(subset=['date'], keep='last')\n",
    "\n",
    "# Handle missing values in classification\n",
    "if sentiment_clean['classification'].isnull().sum() > 0:\n",
    "    print(f\"Warning: Found {sentiment_clean['classification'].isnull().sum()} missing sentiment values\")\n",
    "    sentiment_clean = sentiment_clean.dropna(subset=['classification'])\n",
    "\n",
    "# Standardize classification values\n",
    "sentiment_clean['classification'] = (\n",
    "    sentiment_clean['classification']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "print(f\"Cleaned sentiment data shape: {sentiment_clean.shape}\")\n",
    "print(f\"Date range: {sentiment_clean['date'].min()} to {sentiment_clean['date'].max()}\")\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(sentiment_clean['classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Projects\\trader_sentiment_analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m trader_clean \u001b[38;5;241m=\u001b[39m trader_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert time to datetime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m trader_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mtrader_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract date for merging\u001b[39;00m\n\u001b[0;32m      8\u001b[0m trader_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trader_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
      "File \u001b[1;32md:\\Projects\\trader_sentiment_analysis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Projects\\trader_sentiment_analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "# Clean trader data\n",
    "trader_clean = trader_df.copy()\n",
    "\n",
    "# Convert time to datetime\n",
    "trader_clean['time'] = pd.to_datetime(trader_clean['time'])\n",
    "\n",
    "# Extract date for merging\n",
    "trader_clean['date'] = trader_clean['time'].dt.date\n",
    "trader_clean['date'] = pd.to_datetime(trader_clean['date'])\n",
    "\n",
    "# Remove duplicates\n",
    "initial_rows = len(trader_clean)\n",
    "trader_clean = trader_clean.drop_duplicates()\n",
    "print(f\"Removed {initial_rows - len(trader_clean)} duplicate trade records\")\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"\\nMissing values after initial cleaning:\")\n",
    "print(trader_clean.isnull().sum())\n",
    "\n",
    "# Fill missing closedPnL with 0 (for open positions)\n",
    "trader_clean['closedPnL'] = trader_clean['closedPnL'].fillna(0)\n",
    "\n",
    "# Convert numeric columns\n",
    "numeric_cols = ['size', 'leverage', 'closedPnL']\n",
    "for col in numeric_cols:\n",
    "    if col in trader_clean.columns:\n",
    "        trader_clean[col] = pd.to_numeric(trader_clean[col], errors='coerce')\n",
    "\n",
    "print(f\"\\nCleaned trader data shape: {trader_clean.shape}\")\n",
    "print(f\"Date range: {trader_clean['date'].min()} to {trader_clean['date'].max()}\")\n",
    "print(f\"Unique traders: {trader_clean['account'].nunique()}\")\n",
    "print(f\"Unique symbols: {trader_clean['symbol'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align dates\n",
    "sentiment_clean = sentiment_clean.rename(columns={'Date': 'date'})\n",
    "\n",
    "# Merge trader data with sentiment\n",
    "merged_df = trader_clean.merge(\n",
    "    sentiment_clean[['date', 'Classification']], \n",
    "    on='date', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "print(f\"\\nSentiment coverage:\")\n",
    "print(f\"Trades with sentiment data: {merged_df['Classification'].notna().sum()} ({merged_df['Classification'].notna().sum()/len(merged_df)*100:.2f}%)\")\n",
    "print(f\"Trades without sentiment data: {merged_df['Classification'].isna().sum()} ({merged_df['Classification'].isna().sum()/len(merged_df)*100:.2f}%)\")\n",
    "\n",
    "# For analysis, we'll focus on trades with sentiment data\n",
    "merged_df = merged_df.dropna(subset=['Classification'])\n",
    "print(f\"\\nFinal dataset for analysis: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature Engineering - Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily aggregated metrics per trader\n",
    "daily_trader_metrics = merged_df.groupby(['account', 'date', 'Classification']).agg({\n",
    "    'closedPnL': ['sum', 'mean', 'std', 'count'],\n",
    "    'size': ['sum', 'mean'],\n",
    "    'leverage': ['mean', 'max'],\n",
    "    'side': lambda x: (x == 'Long').sum() / len(x)  # long ratio\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "daily_trader_metrics.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                                  for col in daily_trader_metrics.columns.values]\n",
    "\n",
    "# Rename for clarity\n",
    "daily_trader_metrics = daily_trader_metrics.rename(columns={\n",
    "    'closedPnL_sum': 'daily_pnl',\n",
    "    'closedPnL_mean': 'avg_pnl_per_trade',\n",
    "    'closedPnL_std': 'pnl_volatility',\n",
    "    'closedPnL_count': 'num_trades',\n",
    "    'size_sum': 'total_volume',\n",
    "    'size_mean': 'avg_trade_size',\n",
    "    'leverage_mean': 'avg_leverage',\n",
    "    'leverage_max': 'max_leverage',\n",
    "    'side_<lambda>': 'long_ratio'\n",
    "})\n",
    "\n",
    "# Calculate win rate (percentage of profitable trades)\n",
    "win_rate = merged_df.groupby(['account', 'date']).apply(\n",
    "    lambda x: (x['closedPnL'] > 0).sum() / len(x) if len(x) > 0 else 0\n",
    ").reset_index(name='win_rate')\n",
    "\n",
    "daily_trader_metrics = daily_trader_metrics.merge(win_rate, on=['account', 'date'], how='left')\n",
    "\n",
    "# Fill NaN volatility (single trades) with 0\n",
    "daily_trader_metrics['pnl_volatility'] = daily_trader_metrics['pnl_volatility'].fillna(0)\n",
    "\n",
    "print(\"Daily trader metrics created successfully!\")\n",
    "print(f\"Shape: {daily_trader_metrics.shape}\")\n",
    "display(daily_trader_metrics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall trader-level metrics for segmentation\n",
    "trader_profile = merged_df.groupby('account').agg({\n",
    "    'closedPnL': ['sum', 'mean', 'std'],\n",
    "    'leverage': ['mean', 'max'],\n",
    "    'size': 'mean',\n",
    "    'date': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "trader_profile.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                          for col in trader_profile.columns.values]\n",
    "\n",
    "trader_profile = trader_profile.rename(columns={\n",
    "    'closedPnL_sum': 'total_pnl',\n",
    "    'closedPnL_mean': 'avg_pnl',\n",
    "    'closedPnL_std': 'pnl_std',\n",
    "    'leverage_mean': 'avg_leverage',\n",
    "    'leverage_max': 'max_leverage',\n",
    "    'size_mean': 'avg_size',\n",
    "    'date_count': 'total_trades'\n",
    "})\n",
    "\n",
    "# Calculate overall win rate per trader\n",
    "trader_win_rate = merged_df.groupby('account').apply(\n",
    "    lambda x: (x['closedPnL'] > 0).sum() / len(x)\n",
    ").reset_index(name='overall_win_rate')\n",
    "\n",
    "trader_profile = trader_profile.merge(trader_win_rate, on='account', how='left')\n",
    "\n",
    "# Calculate consistency (coefficient of variation)\n",
    "trader_profile['pnl_consistency'] = 1 / (1 + trader_profile['pnl_std'] / trader_profile['avg_pnl'].abs())\n",
    "trader_profile['pnl_consistency'] = trader_profile['pnl_consistency'].fillna(0)\n",
    "\n",
    "print(\"Trader profiles created successfully!\")\n",
    "print(f\"Shape: {trader_profile.shape}\")\n",
    "display(trader_profile.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Overall Dataset:\")\n",
    "print(f\"  ‚Ä¢ Total trades: {len(merged_df):,}\")\n",
    "print(f\"  ‚Ä¢ Unique traders: {merged_df['account'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Date range: {merged_df['date'].min()} to {merged_df['date'].max()}\")\n",
    "print(f\"  ‚Ä¢ Trading days: {merged_df['date'].nunique():,}\")\n",
    "\n",
    "print(\"\\nüíπ Performance Metrics:\")\n",
    "print(f\"  ‚Ä¢ Total PnL: ${merged_df['closedPnL'].sum():,.2f}\")\n",
    "print(f\"  ‚Ä¢ Average PnL per trade: ${merged_df['closedPnL'].mean():,.2f}\")\n",
    "print(f\"  ‚Ä¢ Median PnL per trade: ${merged_df['closedPnL'].median():,.2f}\")\n",
    "print(f\"  ‚Ä¢ PnL std dev: ${merged_df['closedPnL'].std():,.2f}\")\n",
    "\n",
    "print(\"\\nüìà Sentiment Distribution:\")\n",
    "sentiment_counts = merged_df['Classification'].value_counts()\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"  ‚Ä¢ {sentiment}: {count:,} trades ({count/len(merged_df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Trading Behavior:\")\n",
    "long_pct = (merged_df['side'] == 'Long').sum() / len(merged_df) * 100\n",
    "print(f\"  ‚Ä¢ Long positions: {long_pct:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Short positions: {100-long_pct:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Average leverage: {merged_df['leverage'].mean():.2f}x\")\n",
    "print(f\"  ‚Ä¢ Average trade size: ${merged_df['size'].mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part B: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Performance Comparison: Fear vs Greed Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics by sentiment\n",
    "sentiment_performance = daily_trader_metrics.groupby('Classification').agg({\n",
    "    'daily_pnl': ['mean', 'median', 'std'],\n",
    "    'win_rate': ['mean', 'median'],\n",
    "    'avg_pnl_per_trade': ['mean', 'median'],\n",
    "    'pnl_volatility': 'mean',\n",
    "    'num_trades': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PERFORMANCE METRICS: FEAR vs GREED\")\n",
    "print(\"=\" * 80)\n",
    "display(sentiment_performance)\n",
    "\n",
    "# Statistical tests\n",
    "fear_pnl = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['daily_pnl']\n",
    "greed_pnl = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['daily_pnl']\n",
    "\n",
    "# Mann-Whitney U test (non-parametric)\n",
    "stat, p_value = mannwhitneyu(fear_pnl, greed_pnl, alternative='two-sided')\n",
    "print(f\"\\nüìä Statistical Test (Daily PnL):\")\n",
    "print(f\"  Mann-Whitney U statistic: {stat:.2f}\")\n",
    "print(f\"  P-value: {p_value:.6f}\")\n",
    "print(f\"  Result: {'Statistically significant' if p_value < 0.05 else 'Not statistically significant'} (Œ± = 0.05)\")\n",
    "\n",
    "# Win rate comparison\n",
    "fear_wr = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['win_rate']\n",
    "greed_wr = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['win_rate']\n",
    "stat_wr, p_value_wr = mannwhitneyu(fear_wr, greed_wr, alternative='two-sided')\n",
    "print(f\"\\nüìä Statistical Test (Win Rate):\")\n",
    "print(f\"  Mann-Whitney U statistic: {stat_wr:.2f}\")\n",
    "print(f\"  P-value: {p_value_wr:.6f}\")\n",
    "print(f\"  Result: {'Statistically significant' if p_value_wr < 0.05 else 'Not statistically significant'} (Œ± = 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Performance comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Daily PnL Distribution\n",
    "ax1 = axes[0, 0]\n",
    "for sentiment in ['Fear', 'Greed']:\n",
    "    data = daily_trader_metrics[daily_trader_metrics['Classification'] == sentiment]['daily_pnl']\n",
    "    ax1.hist(data, bins=50, alpha=0.6, label=sentiment, edgecolor='black')\n",
    "ax1.set_xlabel('Daily PnL ($)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('Daily PnL Distribution: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Win Rate Comparison\n",
    "ax2 = axes[0, 1]\n",
    "sentiment_wr = daily_trader_metrics.groupby('Classification')['win_rate'].apply(list)\n",
    "ax2.boxplot([sentiment_wr['Fear'], sentiment_wr['Greed']], labels=['Fear', 'Greed'])\n",
    "ax2.set_ylabel('Win Rate', fontsize=12)\n",
    "ax2.set_title('Win Rate Distribution: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Average PnL per Trade\n",
    "ax3 = axes[1, 0]\n",
    "avg_pnl_sentiment = daily_trader_metrics.groupby('Classification')['avg_pnl_per_trade'].mean()\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "ax3.bar(avg_pnl_sentiment.index, avg_pnl_sentiment.values, color=colors, edgecolor='black')\n",
    "ax3.set_ylabel('Average PnL per Trade ($)', fontsize=12)\n",
    "ax3.set_title('Average PnL per Trade: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. PnL Volatility\n",
    "ax4 = axes[1, 1]\n",
    "volatility_sentiment = daily_trader_metrics.groupby('Classification')['pnl_volatility'].mean()\n",
    "ax4.bar(volatility_sentiment.index, volatility_sentiment.values, color=colors, edgecolor='black')\n",
    "ax4.set_ylabel('Average PnL Volatility ($)', fontsize=12)\n",
    "ax4.set_title('PnL Volatility: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/performance_fear_vs_greed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved: outputs/performance_fear_vs_greed.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Behavioral Changes Based on Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavioral metrics by sentiment\n",
    "behavior_metrics = daily_trader_metrics.groupby('Classification').agg({\n",
    "    'num_trades': ['mean', 'median'],\n",
    "    'avg_leverage': ['mean', 'median'],\n",
    "    'max_leverage': ['mean', 'median'],\n",
    "    'total_volume': ['mean', 'median'],\n",
    "    'long_ratio': ['mean', 'median']\n",
    "}).round(4)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BEHAVIORAL METRICS: FEAR vs GREED\")\n",
    "print(\"=\" * 80)\n",
    "display(behavior_metrics)\n",
    "\n",
    "# Statistical tests for key behavioral changes\n",
    "fear_trades = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['num_trades']\n",
    "greed_trades = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['num_trades']\n",
    "stat_trades, p_trades = mannwhitneyu(fear_trades, greed_trades)\n",
    "\n",
    "fear_lev = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['avg_leverage']\n",
    "greed_lev = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['avg_leverage']\n",
    "stat_lev, p_lev = mannwhitneyu(fear_lev, greed_lev)\n",
    "\n",
    "print(f\"\\nüìä Statistical Tests:\")\n",
    "print(f\"  Trade Frequency: p-value = {p_trades:.6f} ({'significant' if p_trades < 0.05 else 'not significant'})\")\n",
    "print(f\"  Average Leverage: p-value = {p_lev:.6f} ({'significant' if p_lev < 0.05 else 'not significant'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Behavioral changes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Number of Trades\n",
    "ax1 = axes[0, 0]\n",
    "trades_data = [daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['num_trades'],\n",
    "               daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['num_trades']]\n",
    "ax1.boxplot(trades_data, labels=['Fear', 'Greed'])\n",
    "ax1.set_ylabel('Number of Trades per Day', fontsize=12)\n",
    "ax1.set_title('Trading Frequency: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Average Leverage\n",
    "ax2 = axes[0, 1]\n",
    "leverage_data = [daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['avg_leverage'],\n",
    "                 daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['avg_leverage']]\n",
    "ax2.boxplot(leverage_data, labels=['Fear', 'Greed'])\n",
    "ax2.set_ylabel('Average Leverage (x)', fontsize=12)\n",
    "ax2.set_title('Leverage Usage: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Long/Short Ratio\n",
    "ax3 = axes[1, 0]\n",
    "long_ratio_sentiment = daily_trader_metrics.groupby('Classification')['long_ratio'].mean()\n",
    "ax3.bar(long_ratio_sentiment.index, long_ratio_sentiment.values, color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
    "ax3.set_ylabel('Long Position Ratio', fontsize=12)\n",
    "ax3.set_title('Long vs Short Bias: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(0.5, color='black', linestyle='--', alpha=0.5, label='Neutral (50%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Total Volume\n",
    "ax4 = axes[1, 1]\n",
    "volume_sentiment = daily_trader_metrics.groupby('Classification')['total_volume'].mean()\n",
    "ax4.bar(volume_sentiment.index, volume_sentiment.values, color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
    "ax4.set_ylabel('Average Total Volume ($)', fontsize=12)\n",
    "ax4.set_title('Trading Volume: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/behavior_fear_vs_greed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved: outputs/behavior_fear_vs_greed.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Trader Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment 1: High vs Low Leverage Traders\n",
    "leverage_threshold = trader_profile['avg_leverage'].median()\n",
    "trader_profile['leverage_segment'] = trader_profile['avg_leverage'].apply(\n",
    "    lambda x: 'High Leverage' if x >= leverage_threshold else 'Low Leverage'\n",
    ")\n",
    "\n",
    "# Segment 2: Frequent vs Infrequent Traders\n",
    "trade_freq_threshold = trader_profile['total_trades'].quantile(0.75)\n",
    "trader_profile['frequency_segment'] = trader_profile['total_trades'].apply(\n",
    "    lambda x: 'Frequent' if x >= trade_freq_threshold else 'Infrequent'\n",
    ")\n",
    "\n",
    "# Segment 3: Consistent Winners vs Inconsistent Traders\n",
    "# Define winners as positive total PnL AND win rate > 50%\n",
    "trader_profile['performance_segment'] = trader_profile.apply(\n",
    "    lambda row: 'Consistent Winner' if (row['total_pnl'] > 0 and row['overall_win_rate'] > 0.5)\n",
    "    else 'Inconsistent', axis=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRADER SEGMENTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ LEVERAGE SEGMENTATION:\")\n",
    "print(f\"   Threshold: {leverage_threshold:.2f}x\")\n",
    "print(trader_profile['leverage_segment'].value_counts())\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ FREQUENCY SEGMENTATION:\")\n",
    "print(f\"   Threshold: {trade_freq_threshold:.0f} trades\")\n",
    "print(trader_profile['frequency_segment'].value_counts())\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ PERFORMANCE SEGMENTATION:\")\n",
    "print(\"   Criteria: Total PnL > 0 AND Win Rate > 50%\")\n",
    "print(trader_profile['performance_segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge segments back to daily metrics for sentiment analysis\n",
    "daily_with_segments = daily_trader_metrics.merge(\n",
    "    trader_profile[['account', 'leverage_segment', 'frequency_segment', 'performance_segment']], \n",
    "    on='account', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Analyze segment performance by sentiment\n",
    "segment_sentiment_performance = daily_with_segments.groupby(\n",
    "    ['leverage_segment', 'Classification']\n",
    ")['daily_pnl'].agg(['mean', 'median', 'std', 'count']).round(4)\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"SEGMENT PERFORMANCE BY SENTIMENT (Leverage)\")\n",
    "print(\"=\" * 80)\n",
    "display(segment_sentiment_performance)\n",
    "\n",
    "# Frequency segment analysis\n",
    "freq_sentiment_performance = daily_with_segments.groupby(\n",
    "    ['frequency_segment', 'Classification']\n",
    ")['daily_pnl'].agg(['mean', 'median', 'std', 'count']).round(4)\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"SEGMENT PERFORMANCE BY SENTIMENT (Frequency)\")\n",
    "print(\"=\" * 80)\n",
    "display(freq_sentiment_performance)\n",
    "\n",
    "# Performance segment analysis\n",
    "perf_sentiment_analysis = daily_with_segments.groupby(\n",
    "    ['performance_segment', 'Classification']\n",
    ")['daily_pnl'].agg(['mean', 'median', 'std', 'count']).round(4)\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"SEGMENT PERFORMANCE BY SENTIMENT (Performance Profile)\")\n",
    "print(\"=\" * 80)\n",
    "display(perf_sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Segment analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# 1. Leverage Segments\n",
    "ax1 = axes[0]\n",
    "leverage_pivot = daily_with_segments.groupby(['leverage_segment', 'Classification'])['daily_pnl'].mean().unstack()\n",
    "leverage_pivot.plot(kind='bar', ax=ax1, color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
    "ax1.set_xlabel('Leverage Segment', fontsize=12)\n",
    "ax1.set_ylabel('Average Daily PnL ($)', fontsize=12)\n",
    "ax1.set_title('Performance by Leverage: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax1.legend(title='Sentiment')\n",
    "ax1.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Frequency Segments\n",
    "ax2 = axes[1]\n",
    "freq_pivot = daily_with_segments.groupby(['frequency_segment', 'Classification'])['daily_pnl'].mean().unstack()\n",
    "freq_pivot.plot(kind='bar', ax=ax2, color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
    "ax2.set_xlabel('Frequency Segment', fontsize=12)\n",
    "ax2.set_ylabel('Average Daily PnL ($)', fontsize=12)\n",
    "ax2.set_title('Performance by Frequency: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax2.legend(title='Sentiment')\n",
    "ax2.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 3. Performance Segments\n",
    "ax3 = axes[2]\n",
    "perf_pivot = daily_with_segments.groupby(['performance_segment', 'Classification'])['daily_pnl'].mean().unstack()\n",
    "perf_pivot.plot(kind='bar', ax=ax3, color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
    "ax3.set_xlabel('Performance Segment', fontsize=12)\n",
    "ax3.set_ylabel('Average Daily PnL ($)', fontsize=12)\n",
    "ax3.set_title('Performance by Trader Type: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "ax3.legend(title='Sentiment')\n",
    "ax3.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "ax3.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/segment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved: outputs/segment_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive insights table\n",
    "insights_data = []\n",
    "\n",
    "# Insight 1: Overall performance difference\n",
    "fear_mean_pnl = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['daily_pnl'].mean()\n",
    "greed_mean_pnl = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['daily_pnl'].mean()\n",
    "pnl_diff_pct = ((greed_mean_pnl - fear_mean_pnl) / abs(fear_mean_pnl) * 100) if fear_mean_pnl != 0 else 0\n",
    "\n",
    "insights_data.append({\n",
    "    'Insight': 'Performance Differential',\n",
    "    'Metric': 'Average Daily PnL',\n",
    "    'Fear': f'${fear_mean_pnl:.2f}',\n",
    "    'Greed': f'${greed_mean_pnl:.2f}',\n",
    "    'Difference': f'{pnl_diff_pct:+.2f}%'\n",
    "})\n",
    "\n",
    "# Insight 2: Win rate difference\n",
    "fear_wr_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['win_rate'].mean()\n",
    "greed_wr_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['win_rate'].mean()\n",
    "wr_diff = (greed_wr_mean - fear_wr_mean) * 100\n",
    "\n",
    "insights_data.append({\n",
    "    'Insight': 'Win Rate Differential',\n",
    "    'Metric': 'Average Win Rate',\n",
    "    'Fear': f'{fear_wr_mean*100:.2f}%',\n",
    "    'Greed': f'{greed_wr_mean*100:.2f}%',\n",
    "    'Difference': f'{wr_diff:+.2f} pp'\n",
    "})\n",
    "\n",
    "# Insight 3: Leverage behavior\n",
    "fear_lev_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['avg_leverage'].mean()\n",
    "greed_lev_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['avg_leverage'].mean()\n",
    "lev_diff_pct = ((greed_lev_mean - fear_lev_mean) / fear_lev_mean * 100) if fear_lev_mean != 0 else 0\n",
    "\n",
    "insights_data.append({\n",
    "    'Insight': 'Leverage Behavior',\n",
    "    'Metric': 'Average Leverage',\n",
    "    'Fear': f'{fear_lev_mean:.2f}x',\n",
    "    'Greed': f'{greed_lev_mean:.2f}x',\n",
    "    'Difference': f'{lev_diff_pct:+.2f}%'\n",
    "})\n",
    "\n",
    "# Insight 4: Trade frequency\n",
    "fear_trades_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Fear']['num_trades'].mean()\n",
    "greed_trades_mean = daily_trader_metrics[daily_trader_metrics['Classification'] == 'Greed']['num_trades'].mean()\n",
    "trades_diff_pct = ((greed_trades_mean - fear_trades_mean) / fear_trades_mean * 100) if fear_trades_mean != 0 else 0\n",
    "\n",
    "insights_data.append({\n",
    "    'Insight': 'Trading Activity',\n",
    "    'Metric': 'Trades per Day',\n",
    "    'Fear': f'{fear_trades_mean:.2f}',\n",
    "    'Greed': f'{greed_trades_mean:.2f}',\n",
    "    'Difference': f'{trades_diff_pct:+.2f}%'\n",
    "})\n",
    "\n",
    "insights_df = pd.DataFrame(insights_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS: FEAR vs GREED TRADING\")\n",
    "print(\"=\" * 80)\n",
    "display(insights_df)\n",
    "\n",
    "# Save to CSV\n",
    "insights_df.to_csv('../outputs/key_insights.csv', index=False)\n",
    "print(\"\\n‚úÖ Insights saved: outputs/key_insights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part C: Actionable Strategy Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Strategy Framework\n",
    "\n",
    "Based on the analysis above, we propose the following evidence-based trading strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\n",
    "    {\n",
    "        'Strategy': 'Leverage Adjustment Strategy',\n",
    "        'Target Segment': 'High Leverage Traders',\n",
    "        'Rule': 'Reduce leverage by 20-30% during Fear periods',\n",
    "        'Evidence': f'High leverage traders show {segment_sentiment_performance.loc[(\"High Leverage\", \"Fear\"), \"std\"]:.2f} volatility in Fear vs {segment_sentiment_performance.loc[(\"High Leverage\", \"Greed\"), \"std\"]:.2f} in Greed',\n",
    "        'Expected Impact': 'Reduce drawdowns, preserve capital during volatile fear periods'\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'Selective Activity Strategy',\n",
    "        'Target Segment': 'Frequent Traders',\n",
    "        'Rule': 'Reduce trade frequency by 15-25% during Fear days; focus on high-conviction setups only',\n",
    "        'Evidence': f'Frequent traders average {freq_sentiment_performance.loc[(\"Frequent\", \"Fear\"), \"mean\"]:.2f} PnL in Fear vs {freq_sentiment_performance.loc[(\"Frequent\", \"Greed\"), \"mean\"]:.2f} in Greed',\n",
    "        'Expected Impact': 'Improve trade quality, reduce transaction costs during unfavorable sentiment'\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'Counter-Sentiment Position Sizing',\n",
    "        'Target Segment': 'Consistent Winners',\n",
    "        'Rule': 'Maintain or slightly increase position sizes during Fear; reduce exposure during extreme Greed',\n",
    "        'Evidence': f'Consistent winners maintain positive PnL across both sentiments (Fear: {perf_sentiment_analysis.loc[(\"Consistent Winner\", \"Fear\"), \"mean\"]:.2f}, Greed: {perf_sentiment_analysis.loc[(\"Consistent Winner\", \"Greed\"), \"mean\"]:.2f})',\n",
    "        'Expected Impact': 'Capitalize on market overreactions, fade extreme sentiment'\n",
    "    }\n",
    "]\n",
    "\n",
    "strategies_df = pd.DataFrame(strategies)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ACTIONABLE TRADING STRATEGIES\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in strategies_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STRATEGY {idx+1}: {row['Strategy']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"üéØ Target: {row['Target Segment']}\")\n",
    "    print(f\"üìã Rule: {row['Rule']}\")\n",
    "    print(f\"üìä Evidence: {row['Evidence']}\")\n",
    "    print(f\"üí° Impact: {row['Expected Impact']}\")\n",
    "\n",
    "# Save strategies\n",
    "strategies_df.to_csv('../outputs/trading_strategies.csv', index=False)\n",
    "print(\"\\n‚úÖ Strategies saved: outputs/trading_strategies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementation Guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create implementation checklist\n",
    "implementation = {\n",
    "    'Phase 1: Setup (Week 1)': [\n",
    "        'Integrate daily Fear/Greed sentiment feed into trading dashboard',\n",
    "        'Classify traders into segments (leverage, frequency, performance)',\n",
    "        'Set up automated alerts for sentiment regime changes'\n",
    "    ],\n",
    "    'Phase 2: Pilot (Weeks 2-4)': [\n",
    "        'Test strategies with 10-20% of capital per segment',\n",
    "        'Monitor daily PnL impact vs control group',\n",
    "        'Collect feedback from traders on rule practicality'\n",
    "    ],\n",
    "    'Phase 3: Scale (Month 2+)': [\n",
    "        'Roll out successful strategies to full segments',\n",
    "        'Implement automated risk controls based on sentiment',\n",
    "        'Continuously monitor and refine thresholds'\n",
    "    ],\n",
    "    'Key Metrics to Track': [\n",
    "        'Sharpe ratio improvement by segment',\n",
    "        'Maximum drawdown reduction',\n",
    "        'Win rate and profit factor changes',\n",
    "        'Strategy adherence rate'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IMPLEMENTATION ROADMAP\")\n",
    "print(\"=\" * 80)\n",
    "for phase, items in implementation.items():\n",
    "    print(f\"\\n{phase}:\")\n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"  {i}. {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Predictive Modeling (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for predictive modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create target variable: profitable day (1) vs unprofitable day (0)\n",
    "modeling_df = daily_with_segments.copy()\n",
    "modeling_df['profitable_day'] = (modeling_df['daily_pnl'] > 0).astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "le_sentiment = LabelEncoder()\n",
    "le_leverage = LabelEncoder()\n",
    "le_frequency = LabelEncoder()\n",
    "le_performance = LabelEncoder()\n",
    "\n",
    "modeling_df['sentiment_encoded'] = le_sentiment.fit_transform(modeling_df['Classification'])\n",
    "modeling_df['leverage_seg_encoded'] = le_leverage.fit_transform(modeling_df['leverage_segment'])\n",
    "modeling_df['frequency_seg_encoded'] = le_frequency.fit_transform(modeling_df['frequency_segment'])\n",
    "modeling_df['performance_seg_encoded'] = le_performance.fit_transform(modeling_df['performance_segment'])\n",
    "\n",
    "# Feature engineering\n",
    "modeling_df['day_of_week'] = modeling_df['date'].dt.dayofweek\n",
    "modeling_df['win_rate_lag'] = modeling_df.groupby('account')['win_rate'].shift(1).fillna(0.5)\n",
    "modeling_df['pnl_lag'] = modeling_df.groupby('account')['daily_pnl'].shift(1).fillna(0)\n",
    "\n",
    "# Select features\n",
    "feature_cols = [\n",
    "    'sentiment_encoded', 'leverage_seg_encoded', 'frequency_seg_encoded', \n",
    "    'performance_seg_encoded', 'num_trades', 'avg_leverage', 'long_ratio',\n",
    "    'day_of_week', 'win_rate_lag', 'pnl_lag'\n",
    "]\n",
    "\n",
    "# Remove rows with missing values\n",
    "modeling_df_clean = modeling_df[feature_cols + ['profitable_day']].dropna()\n",
    "\n",
    "X = modeling_df_clean[feature_cols]\n",
    "y = modeling_df_clean['profitable_day']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREDICTIVE MODEL: NEXT-DAY PROFITABILITY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Target distribution (train): {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Unprofitable', 'Profitable']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "display(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('Importance Score', fontsize=12)\n",
    "ax.set_title('Feature Importance for Profitability Prediction', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved: outputs/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Export\n",
    "\n",
    "This analysis has completed:\n",
    "1. ‚úÖ Data cleaning and preparation\n",
    "2. ‚úÖ Performance comparison (Fear vs Greed)\n",
    "3. ‚úÖ Behavioral analysis\n",
    "4. ‚úÖ Trader segmentation\n",
    "5. ‚úÖ Actionable strategy recommendations\n",
    "6. ‚úÖ Predictive modeling (bonus)\n",
    "\n",
    "All outputs have been saved to the `outputs/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final datasets\n",
    "daily_trader_metrics.to_csv('../outputs/daily_trader_metrics.csv', index=False)\n",
    "trader_profile.to_csv('../outputs/trader_profiles.csv', index=False)\n",
    "daily_with_segments.to_csv('../outputs/daily_metrics_with_segments.csv', index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE - ALL FILES SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìÅ Output Files:\")\n",
    "print(\"  ‚Ä¢ outputs/performance_fear_vs_greed.png\")\n",
    "print(\"  ‚Ä¢ outputs/behavior_fear_vs_greed.png\")\n",
    "print(\"  ‚Ä¢ outputs/segment_analysis.png\")\n",
    "print(\"  ‚Ä¢ outputs/feature_importance.png\")\n",
    "print(\"  ‚Ä¢ outputs/key_insights.csv\")\n",
    "print(\"  ‚Ä¢ outputs/trading_strategies.csv\")\n",
    "print(\"  ‚Ä¢ outputs/daily_trader_metrics.csv\")\n",
    "print(\"  ‚Ä¢ outputs/trader_profiles.csv\")\n",
    "print(\"  ‚Ä¢ outputs/daily_metrics_with_segments.csv\")\n",
    "print(\"\\nüéâ Ready for submission!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
